{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1xs1v9KOg-u",
        "outputId": "d3ef0004-f74f-4e44-eac8-dc210cc5f0ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (23.0)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (2.0.0+cu118)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (3.11.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.11.4\n",
            "Working on device:  cpu\n",
            "Downloading movielens data...\n",
            "Extracting...\n",
            "Loading Files to Memory\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import OrderedDict,defaultdict\n",
        "import datetime\n",
        "import os \n",
        "\n",
        "##\\\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchmetrics import MeanAbsoluteError\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Working on device: \", device)\n",
        "# Download MovieLens data.\n",
        "print(\"Downloading movielens data...\")\n",
        "from urllib.request import urlretrieve\n",
        "import zipfile\n",
        "urlretrieve(\"https://files.grouplens.org/datasets/movielens/ml-1m.zip\", \"movielens.zip\")\n",
        "print(\"Extracting...\")\n",
        "zip_ref = zipfile.ZipFile('movielens.zip', \"r\")\n",
        "zip_ref.extractall()\n",
        "print(\"Loading Files to Memory\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ahy15WyRDfn"
      },
      "outputs": [],
      "source": [
        "with open(\"ml-1m/movies.dat\", \"r+\", encoding = \"utf-8\") as file:\n",
        "    file.seek(0, os.SEEK_END)\n",
        "    pos = file.tell() - 1\n",
        "    file.seek(pos, os.SEEK_SET)\n",
        "    if pos > 0:\n",
        "        file.seek(pos, os.SEEK_SET)\n",
        "        file.truncate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrACOnn_P6Pw"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klLWHvDPPbqX"
      },
      "outputs": [],
      "source": [
        "movie_header = [\"movieId\",\"title\",\"genres\"]\n",
        "movie_pd = pd.read_csv(\"ml-1m/movies.dat\",names=movie_header, sep=':{2}', engine='python')\n",
        "user_header=[\"userId\", \"gender\", \"age\", \"occupation\", \"zip\"]\n",
        "user_pd = pd.read_csv(\"ml-1m/users.dat\", names=user_header, sep=':{2}', engine='python')\n",
        "ratings_header = [\"userId\",\"movieId\",\"rating\",\"timestamp\"]\n",
        "ratings_pd = pd.read_csv(\"ml-1m/ratings.dat\", names=ratings_header, sep=':{2}', engine='python')\n",
        "genere_list = {\"\",\"Action\",\"Adventure\",\"Animation\",\"Children's\",\"Comedy\",\"Crime\",\"Documentary\",\"Drama\",\"Fantasy\",\"Film-Noir\",\"Horror\",\"Musical\",\"Mystery\",\"Romance\",\"Sci-Fi\",\"Thriller\",\"War\",\"Western\"}\n",
        "#Get data lengths\n",
        "movies_size= len(movie_pd)\n",
        "user_size = ratings_pd[\"userId\"].nunique()\n",
        "genere_size = len(genere_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrOZHyPuQJlb",
        "outputId": "ca6076e5-c68e-46e4-fd66-851bd36bbede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coverting Movie Id\n",
            "Coverting User Id\n",
            "Preprocess Complete\n"
          ]
        }
      ],
      "source": [
        "#DATA PREPROCESSING#\n",
        "print(\"Coverting Movie Id\")\n",
        "#Convert Movie Id to zero index\n",
        "id_to_index = dict()\n",
        "index_to_id = dict()\n",
        "for i in range(0, len(movie_pd)) :\n",
        "    index_to_id[i] = movie_pd.iloc[i].movieId\n",
        "    id_to_index[movie_pd.iloc[i].movieId] = i\n",
        "movie_pd['movieId'] = movie_pd['movieId'].map(lambda id: id_to_index[id])\n",
        "ratings_pd['movieId'] = ratings_pd['movieId'].map(lambda id: id_to_index[id])\n",
        "\n",
        "print(\"Coverting User Id\")\n",
        "#Covert User Id to zero index\n",
        "for i in range(0, len(user_pd)) :\n",
        "    id_to_index[user_pd.iloc[i].userId] = i\n",
        "user_pd['userId'] = user_pd['userId'].map(lambda id: id_to_index[id])\n",
        "ratings_pd['userId'] = ratings_pd['userId'].map(lambda id: id_to_index[id])\n",
        "\n",
        "#Get Genere dicts\n",
        "genere_to_id = dict()\n",
        "id_to_genere = dict()\n",
        "for idx,genere in enumerate(genere_list):\n",
        "    genere_to_id[genere] = idx\n",
        "    id_to_genere[idx] = genere\n",
        "\n",
        "#Get data lengths\n",
        "movies_size= len(movie_pd)\n",
        "user_size = ratings_pd[\"userId\"].nunique()\n",
        "genere_size = len(genere_list)\n",
        "#normalize rating\n",
        "# ratings_pd['rating'] = (ratings_pd['rating'] - ratings_pd['rating'].min()) / (ratings_pd['rating'].max() - ratings_pd['rating'].min())    \n",
        "#normalize year\n",
        "def tryconvert(movie):\n",
        "    try:\n",
        "        return int(movie[-5:-1])\n",
        "    except (ValueError, TypeError):\n",
        "        return 2000\n",
        "movie_pd['year'] = movie_pd['title'].map(lambda movie: tryconvert(movie))\n",
        "# movie_pd['year'] = (movie_pd['year'] - movie_pd['year'].min()) / (movie_pd['year'].max() - movie_pd['year'].min())    \n",
        "def encode_gender(gen):\n",
        "    if gen == \"M\": return 1 \n",
        "    else: return 0\n",
        "user_pd['gender'] = user_pd['gender'].map(lambda gender: encode_gender(gender))\n",
        "def encode_age(age):\n",
        "  if age == 1: return 1 #under 18\n",
        "  elif age == 18: return 2 #18-24\n",
        "  elif age == 25: return 3 #25-34\n",
        "  elif age == 35: return 4 # 35-44\n",
        "  elif age == 45: return 5 # 45-49\n",
        "  elif age == 50: return 6 # 50-55\n",
        "  elif age == 56: return 7 # 56+\n",
        "  else: return 0 #unkown\n",
        "user_pd['age'] = user_pd['age'].map(lambda age: encode_age(age))\n",
        "user_pd=user_pd.drop(labels=\"zip\",axis=1)\n",
        "print(\"Preprocess Complete\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "GonTVneUV6ue",
        "outputId": "7882a094-ad13-4c0c-c4fc-b19a9c1ace98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         userId  movieId  rating  timestamp\n",
              "0             0     1176       5  978300760\n",
              "1             0      655       3  978302109\n",
              "2             0      902       3  978301968\n",
              "3             0     3339       4  978300275\n",
              "4             0     2286       5  978824291\n",
              "...         ...      ...     ...        ...\n",
              "1000204    6039     1075       1  956716541\n",
              "1000205    6039     1078       5  956704887\n",
              "1000206    6039      558       5  956704746\n",
              "1000207    6039     1080       4  956715648\n",
              "1000208    6039     1081       4  956715569\n",
              "\n",
              "[1000209 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c0f5a28-d895-483f-ac01-5eea4753db01\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1176</td>\n",
              "      <td>5</td>\n",
              "      <td>978300760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>655</td>\n",
              "      <td>3</td>\n",
              "      <td>978302109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>902</td>\n",
              "      <td>3</td>\n",
              "      <td>978301968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3339</td>\n",
              "      <td>4</td>\n",
              "      <td>978300275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>2286</td>\n",
              "      <td>5</td>\n",
              "      <td>978824291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000204</th>\n",
              "      <td>6039</td>\n",
              "      <td>1075</td>\n",
              "      <td>1</td>\n",
              "      <td>956716541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000205</th>\n",
              "      <td>6039</td>\n",
              "      <td>1078</td>\n",
              "      <td>5</td>\n",
              "      <td>956704887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000206</th>\n",
              "      <td>6039</td>\n",
              "      <td>558</td>\n",
              "      <td>5</td>\n",
              "      <td>956704746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000207</th>\n",
              "      <td>6039</td>\n",
              "      <td>1080</td>\n",
              "      <td>4</td>\n",
              "      <td>956715648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000208</th>\n",
              "      <td>6039</td>\n",
              "      <td>1081</td>\n",
              "      <td>4</td>\n",
              "      <td>956715569</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000209 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c0f5a28-d895-483f-ac01-5eea4753db01')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c0f5a28-d895-483f-ac01-5eea4753db01 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c0f5a28-d895-483f-ac01-5eea4753db01');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saq-nsKi7HYJ"
      },
      "outputs": [],
      "source": [
        "# shuffle 90 | 10 split -- New Sample\n",
        "new_samples = False\n",
        "if new_samples:\n",
        "  train_pd, test_pd = np.split(ratings_pd.sample(frac=1), [int(.9*len(ratings_pd))])\n",
        "  train_pd.to_csv('train_pd.csv', header=False, index=False)\n",
        "  test_pd.to_csv('test_pd.csv', header=False, index=False)\n",
        "else:\n",
        "  #Load Previous Sample\n",
        "  host_path=\"/content/drive/MyDrive/Samples/\"\n",
        "  train_pd = pd.read_csv(host_path + 'train_pd.csv')\n",
        "  test_pd = pd.read_csv(host_path + 'test_pd.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKZWwQ_LTIY7"
      },
      "outputs": [],
      "source": [
        "#HYPER PARAMS\n",
        "args = {\n",
        "    \"batch_size\" : 512,\n",
        "    \"embedding_size\" : 25,\n",
        "    \"layer_size\": 1024,\n",
        "    \"epoch\": 1,\n",
        "    \"lr\": 0.1,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbIWsRViTBmP"
      },
      "outputs": [],
      "source": [
        "class ItemDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        movie_id = torch.tensor(ratings_pd.iloc[index][\"movieId\"], dtype=torch.long)\n",
        "        user_id =  torch.tensor(ratings_pd.iloc[index][\"userId\"], dtype=torch.long)\n",
        "\n",
        "        nfeatures =  torch.tensor([movie_pd.iloc[movie_id.item()][\"year\"],user_pd.iloc[user_id.item()][\"gender\"] , user_pd.iloc[user_id.item()][\"age\"] , user_pd.iloc[user_id.item()][\"occupation\"]], dtype=torch.float32)\n",
        "\n",
        "        genere_split = torch.tensor([genere_to_id[x] for x in movie_pd.iloc[movie_id.item()][\"genres\"].split(\"|\")])\n",
        "        genere_ids = torch.nn.functional.pad(genere_split,(0,20-genere_split.shape[0] ))\n",
        "        label = torch.tensor(ratings_pd.iloc[index][\"rating\"], dtype=torch.float32)\n",
        "\n",
        "        return movie_id, user_id, genere_ids, nfeatures, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "train_dataset = ItemDataset(train_pd)\n",
        "train_loader = DataLoader(train_dataset, batch_size=args[\"batch_size\"], shuffle=True)\n",
        "test_dataset = ItemDataset(test_pd)\n",
        "test_loader = DataLoader(test_dataset, batch_size=args[\"batch_size\"], shuffle=True)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihnbpHwAcV-x"
      },
      "outputs": [],
      "source": [
        "loss_vals = []\n",
        "loss_validation = []\n",
        "class RatingPredModel(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(RatingPredModel, self).__init__()\n",
        "        self.user_embed = nn.Embedding(user_size, args[\"embedding_size\"], device=device)       \n",
        "        self.movie_embed = nn.Embedding(movies_size, args[\"embedding_size\"], device=device)\n",
        "        self.genere_embed = nn.Embedding(genere_size, args[\"embedding_size\"], device=device)\n",
        "\n",
        "        self.optimizer = optim.Adam(self.parameters())\n",
        "        self.loss_fn = nn.MSELoss()\n",
        "\n",
        "        self.bottom_mlp =  nn.Sequential(OrderedDict([\n",
        "          ('ll1', nn.Linear(4 ,args[\"embedding_size\"])),\n",
        "          (\"drop\",  nn.Dropout(p=0.25, inplace=False)),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('norm', nn.BatchNorm1d(args[\"embedding_size\"])),\n",
        "        ]))\n",
        "\n",
        "        self.fc1 = nn.Sequential(OrderedDict([\n",
        "          ('ll2', nn.Linear(args[\"layer_size\"] ,args[\"layer_size\"])),\n",
        "          (\"drop\",  nn.Dropout(p=0.25, inplace=False)),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('norm', nn.BatchNorm1d(args[\"layer_size\"])),\n",
        "        ]))\n",
        "\n",
        "        self.combined_mlp = nn.Sequential(OrderedDict([\n",
        "          ('ll1', nn.Linear(args[\"embedding_size\"] * 5 ,args[\"layer_size\"])),\n",
        "          (\"drop\",  nn.Dropout(p=0.25, inplace=False)),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('norm', nn.BatchNorm1d(args[\"layer_size\"])),\n",
        "          ('fc1',  self.fc1),\n",
        "          ('fc1',  self.fc1),\n",
        "          ('fc1',  self.fc1),\n",
        "          ('ll3', nn.Linear(args[\"layer_size\"] , args[\"embedding_size\"])),\n",
        "          (\"drop\",  nn.Dropout(p=0.25, inplace=False)),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('norm2', nn.BatchNorm1d(args[\"embedding_size\"])),\n",
        "        ]))\n",
        "\n",
        "        self.logits = nn.Sequential(OrderedDict([\n",
        "          ('ll1', nn.Linear(args[\"embedding_size\"] * 2 ,args[\"embedding_size\"] )),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('ll2', nn.Linear(args[\"embedding_size\"], 1)),\n",
        "          # ('sig', nn.Sigmoid())\n",
        "\n",
        "        ]))\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax()\n",
        "        self.aggregation_layer = torch.nn.Conv1d(in_channels=20, out_channels=1, kernel_size=1)\n",
        "        self.mean_absolute_error = MeanAbsoluteError()\n",
        "    def forward(self, movie_id, user_id,genere_ids, nfeatures):\n",
        "\n",
        "\n",
        "        movie_vector = self.movie_embed(movie_id)\n",
        "        user_vector = self.user_embed(user_id)\n",
        "        genere_vector = self.genere_embed(genere_ids)\n",
        "        genere_vector = self.aggregation_layer(genere_vector).squeeze(1)\n",
        "        \n",
        "        #bottom_mlp\n",
        "        nfeature_vector = self.bottom_mlp(nfeatures)\n",
        "        #cross\n",
        "        cross = movie_vector * user_vector * genere_vector * nfeature_vector\n",
        "\n",
        "        #concat\n",
        "        combined = torch.cat((movie_vector,user_vector, genere_vector, nfeature_vector,cross), dim=1)\n",
        "        combined = self.combined_mlp(combined)\n",
        "\n",
        "        #combine\n",
        "        full = torch.cat((cross,combined), dim=1)\n",
        "        return self.logits(full)\n",
        "    \n",
        "    def one_epoch(self,train_loader):\n",
        "        running_loss = 0.\n",
        "        last_loss = 0.\n",
        "        for i,data in enumerate(train_loader):\n",
        "            movie_id, user_id, genere_ids,nfeatures,label  = data\n",
        "            movie_id, user_id, genere_ids,nfeatures, label = movie_id.to(device), user_id.to(device), genere_ids.to(device),nfeatures.to(device), label.to(device)\n",
        "\n",
        "            self.zero_grad()\n",
        "            outputs = self.forward(movie_id, user_id,genere_ids,nfeatures).squeeze()\n",
        "            loss = self.loss_fn(outputs, label)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            if i % 100 == 99:\n",
        "                with torch.no_grad():\n",
        "                  last_loss = running_loss / 100 # loss per batch\n",
        "                  print('  batch {}/{} MSE loss: {} '.format(i + 1, len(train_loader), last_loss))\n",
        "\n",
        "                  running_loss = 0.\n",
        "        return last_loss\n",
        "    def fit(self, train_loader, epoch=args[\"epoch\"], lr=args[\"lr\"]):\n",
        "        \n",
        "        for ep in range(epoch) :\n",
        "            print('EPOCH {}:'.format(ep + 1))\n",
        "            self.train(True)\n",
        "            avg_loss = self.one_epoch(train_loader)\n",
        "            self.train(False)\n",
        "            running_vloss = 0.0\n",
        "            with torch.no_grad():\n",
        "              for i, vdata in enumerate(test_loader):\n",
        "                  vmovie_id, vuser_id, vgenere_ids, vnfeatures, vlabels  = vdata \n",
        "                  vmovie_id, vuser_id, vgenere_ids, vnfeatures, vlabels = vmovie_id.to(device), vuser_id.to(device), vgenere_ids.to(device), vnfeatures.to(device), vlabels.to(device)\n",
        "\n",
        "                  \n",
        "                  voutputs = self.forward(vmovie_id, vuser_id, vgenere_ids,vnfeatures).squeeze()\n",
        "                  vloss =  torch.sqrt(self.loss_fn(voutputs, vlabels))\n",
        "                  running_vloss += vloss\n",
        "            avg_vloss = running_vloss / (i + 1)\n",
        "            print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "            loss_vals.append(avg_loss)\n",
        "            loss_validation.append(avg_vloss)\n",
        "            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "            model_path = '/content/drive/MyDrive/weights/movierec/rmse_cross{}_{}_{}_{}'.format(timestamp, ep+1 ,avg_loss, avg_vloss)\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "    def get_metrics(self):\n",
        "      with torch.no_grad():\n",
        "            running_rmse = 0\n",
        "            running_mae = 0\n",
        "            for i, vdata in enumerate(test_loader):\n",
        "                vmovie_id, vuser_id, vgenere_ids, vnfeatures, vlabels  = vdata \n",
        "                vmovie_id, vuser_id, vgenere_ids, vnfeatures, vlabels = vmovie_id.to(device), vuser_id.to(device), vgenere_ids.to(device), vnfeatures.to(device), vlabels.to(device)\n",
        "\n",
        "                \n",
        "                voutputs = self.forward(vmovie_id, vuser_id, vgenere_ids,vnfeatures).squeeze()\n",
        "                running_rmse +=  torch.sqrt(self.loss_fn(voutputs, vlabels))\n",
        "                running_mae += self.mean_absolute_error(voutputs,vlabels)\n",
        "            rmse =  running_rmse / (i + 1)\n",
        "            mae = running_mae / (i + 1)\n",
        "            print('RMSE loss: {}\\tMAE{} '.format(rmse, mae))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvTFIHPpddNQ"
      },
      "outputs": [],
      "source": [
        "model = RatingPredModel(args).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9pwfFGF5xlF",
        "outputId": "51fc768e-f36b-4b11-b7fd-49b7bda5208e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "PATH = \"/content/drive/MyDrive/weights/movierec/rmse_cross20230415_162933_3_0.37703907549381255_0.5121314525604248\"\n",
        "model.load_state_dict(torch.load(PATH, map_location=torch.device(device)), strict=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0jTX3q5dgRY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "f2245b85-80ea-4d01-a65d-48ca6be8f381"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 1:\n",
            "  batch 100/1759 MSE loss: 13.991343336105347 \n",
            "  batch 200/1759 MSE loss: 13.997267017364502 \n",
            "  batch 300/1759 MSE loss: 14.034649829864502 \n",
            "  batch 400/1759 MSE loss: 14.030696182250976 \n",
            "  batch 500/1759 MSE loss: 13.988768663406372 \n",
            "  batch 600/1759 MSE loss: 13.980334978103638 \n",
            "  batch 700/1759 MSE loss: 14.010077676773072 \n",
            "  batch 800/1759 MSE loss: 13.990192108154297 \n",
            "  batch 900/1759 MSE loss: 13.981048974990845 \n",
            "  batch 1000/1759 MSE loss: 13.970403242111207 \n",
            "  batch 1100/1759 MSE loss: 14.00684398651123 \n",
            "  batch 1200/1759 MSE loss: 13.959441003799439 \n",
            "  batch 1300/1759 MSE loss: 14.007606706619264 \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-6263318c06da>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-62-08880900f2b6>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_loader, epoch, lr)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'EPOCH {}:'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mrunning_vloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-62-08880900f2b6>\u001b[0m in \u001b[0;36mone_epoch\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mlast_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mmovie_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenere_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mmovie_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenere_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovie_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenere_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-1c01f07374c3>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmovie_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings_pd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"movieId\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0muser_id\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings_pd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"userId\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mnfeatures\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmovie_pd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmovie_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"year\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser_pd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gender\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0muser_pd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"age\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0muser_pd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"occupation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1625\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1627\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3721\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3722\u001b[0m             )\n\u001b[0;32m-> 3723\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3724\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_is_copy\u001b[0;34m(self, ref, copy)\u001b[0m\n\u001b[1;32m   4118\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4119\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mref\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4120\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_is_chained_assignment_possible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool_t\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "model.fit(train_loader, epoch=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_metrics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUPafCzoE2Sr",
        "outputId": "db70f322-8473-4efa-b621-5fcbcf266d47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-1c01f07374c3>:6: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
            "  movie_id = torch.tensor(ratings_pd.iloc[index][\"movieId\"], dtype=torch.long)\n",
            "<ipython-input-15-1c01f07374c3>:7: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
            "  user_id =  torch.tensor(ratings_pd.iloc[index][\"userId\"], dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE loss: 0.38286659121513367\tMAE0.31443578004837036 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUsxsw1mqvVB"
      },
      "outputs": [],
      "source": [
        "def ranking(query_liked):\n",
        "    with torch.no_grad():\n",
        "        weights = model.movie_embed.weight.detach().cpu().numpy()\n",
        "        query_res = weights[query_liked].sum(axis=0)\n",
        "\n",
        "        outs = list()\n",
        "        for idx,movie in movie_pd[\"title\"].items():\n",
        "            movie = weights[idx]\n",
        "            vector_dot = np.dot(movie, query_res)\n",
        "            movie_1_length = np.linalg.norm(movie,2)\n",
        "            query_length = np.linalg.norm(query_res,2)\n",
        "            cosine_dist =  (vector_dot / (movie_1_length * query_length))\n",
        "            outs.append(cosine_dist)\n",
        "        return torch.tensor(np.stack(outs,0))\n",
        "    \n",
        "def display_top_k(score, indices, k=5):\n",
        "    top_scores = score[:k]\n",
        "    top_indic = indices[:k]\n",
        "    top_names = []\n",
        "    top_generes = []\n",
        "    for movie_id in top_indic:\n",
        "        top_names.append(movie_pd.loc[movie_id.item()][\"title\"])\n",
        "        top_generes.append(movie_pd.loc[movie_id.item()][\"genres\"])\n",
        "        \n",
        "    df = pd.DataFrame({\n",
        "        \"score_key\": top_scores.numpy(),\n",
        "        'titles':top_names,\n",
        "        'genres': top_generes\n",
        "    })\n",
        "    print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAl18Vxsubr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2a94b84-9a2e-4962-e7d5-ca9a00390080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===========COSINE SIMILARITY===================\n",
            "   score_key                              titles                    genres\n",
            "0   1.000000           Gone in 60 Seconds (2000)              Action|Crime\n",
            "1   0.741664                It's My Party (1995)                     Drama\n",
            "2   0.688896                     Dinosaur (2000)      Animation|Children's\n",
            "3   0.683477     Honey, I Blew Up the Kid (1992)  Children's|Comedy|Sci-Fi\n",
            "4   0.678023                  Brassed Off (1996)      Comedy|Drama|Romance\n",
            "5   0.673571                  White Sands (1992)            Drama|Thriller\n",
            "6   0.663483  Kestrel's Eye (Falkens �ga) (1998)               Documentary\n",
            "7   0.661258                    King Kong (1976)   Action|Adventure|Horror\n",
            "8   0.657639                    Star Maps (1997)                     Drama\n",
            "9   0.647694              Pather Panchali (1955)                     Drama\n"
          ]
        }
      ],
      "source": [
        "query_liked = [0] #Toy Story\n",
        "# query_liked = [224] #Star  Wars\n",
        "# query_liked = [257] #Pulp Fiction\n",
        "query_liked = [3648] \n",
        "\n",
        "\n",
        "topk = 10\n",
        "\n",
        "print(\"===========COSINE SIMILARITY===================\")\n",
        "score, indices = ranking(query_liked).sort(descending=True)\n",
        "display_top_k(score,indices, topk)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "predictions = defaultdict(list)\n",
        "model.eval()\n",
        "for userid, user in user_pd[:600].iterrows():\n",
        "  print(f\"{userid+1}/{len(user_pd[:600])}\")\n",
        "  for movieid, movie in movie_pd.iterrows():\n",
        "    movie_id = torch.tensor([movie['movieId']], dtype=torch.long).to(device)\n",
        "\n",
        "    user_id = torch.tensor([user['userId']] , dtype=torch.long ).to(device)\n",
        "\n",
        "    genere_split = torch.tensor([genere_to_id[x] for x in movie[\"genres\"].split(\"|\")])\n",
        "    genere_ids = torch.nn.functional.pad(genere_split,(0,20-genere_split.shape[0] )).unsqueeze(0).to(device)\n",
        "    \n",
        "    nfeatures = torch.tensor([[movie[\"year\"], user[\"gender\"], user['age'], user['occupation']]] , dtype=torch.float32).to(device)\n",
        "\n",
        "\n",
        "    pred = model.forward(movie_id, user_id,genere_ids,nfeatures).item()\n",
        "    predictions[user_id.item()].append((movie_id.item(), pred))\n",
        "#For each user \n",
        "  # For each movie\n",
        "    #insert dict rating\n",
        "  #organize ratings keep to k"
      ],
      "metadata": {
        "id": "1Z-C7kS4RkU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arsGtyLjfoJG",
        "outputId": "6b14265b-46ea-4ee4-b73a-8174e96a9025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle \n",
        "PATH = \"/content/drive/MyDrive/weights/movierec/dict_600.pkl\"\n",
        "with open(PATH, 'wb') as f:\n",
        "    pickle.dump(predictions, f)"
      ],
      "metadata": {
        "id": "3g6QwIMj0fwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle \n",
        "\n",
        "PATH = \"/content/drive/MyDrive/weights/movierec/dict_10.pkl\"\n",
        "with open(PATH, 'rb') as f:\n",
        "    predictions = pickle.load(f)\n",
        "print(len(predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M-S4fvw14wG",
        "outputId": "e73b3525-3613-480a-83ff-086e24692ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[1]"
      ],
      "metadata": {
        "id": "dnRaaleRVJ4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics(k, thresh):\n",
        "  score = 0.0\n",
        "  total = 0.0\n",
        "\n",
        "  precisions = dict()\n",
        "  recalls = dict()\n",
        "  for id, pred in predictions.items():\n",
        "    predictions[id].sort(key = lambda x: x[1], reverse=True)\n",
        "\n",
        "    n_rel = sum((true_r >= thresh) for (_, true_r) in pred)\n",
        "    n_rec_k = sum((est >= thresh) for (est, _) in pred[:k])\n",
        "    n_rel_and_rec_k = sum(\n",
        "        ((true_r >= thresh) and (est >= thresh))\n",
        "        for (est, true_r) in pred[:k]\n",
        "    )\n",
        "\n",
        "    precisions[id] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
        "    recalls[id] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
        "  return precisions, recalls\n",
        "  #   for rating in pred[:k]:\n",
        "  #     total += 1.0\n",
        "  #     if rating[1] >= thresh:\n",
        "  #       score += 1.0\n",
        "  # print(score/total)\n",
        "\n",
        "\n",
        "p, r = get_metrics(5, 0.365)\n",
        "  \n",
        "avg_p = sum(p.values()) / len(p.values()) * 100\n",
        "avg_r = sum(r.values()) / len(r.values()) * 100\n",
        "\n",
        "\n",
        "print(f\"Precision: {avg_p}\\tRecall: {avg_r}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrTuuiZFSlUU",
        "outputId": "0036d82c-b53a-487e-e786-513cf199d30b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 78.0\tRecall: 72.36652236652236\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}