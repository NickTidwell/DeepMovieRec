{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDno1WN38EMu",
        "outputId": "7b5364d7-18d2-441d-a7df-5076e0bbe234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on device:  cpu\n",
            "Downloading movielens data...\n",
            "Extracting...\n",
            "Loading Files to Memory\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "import datetime\n",
        "import os \n",
        "from torchmetrics import MeanAbsoluteError\n",
        "\n",
        "##\\\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Working on device: \", device)\n",
        "# Download MovieLens data.\n",
        "print(\"Downloading movielens data...\")\n",
        "from urllib.request import urlretrieve\n",
        "import zipfile\n",
        "urlretrieve(\"https://files.grouplens.org/datasets/movielens/ml-1m.zip\", \"movielens.zip\")\n",
        "print(\"Extracting...\")\n",
        "zip_ref = zipfile.ZipFile('movielens.zip', \"r\")\n",
        "zip_ref.extractall()\n",
        "print(\"Loading Files to Memory\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqJzwkX183PU"
      },
      "outputs": [],
      "source": [
        "movie_header = [\"movieId\",\"title\",\"genres\"]\n",
        "movie_pd = pd.read_csv(\"ml-1m/movies.dat\",names=movie_header, sep=':{2}', engine='python')\n",
        "user_header=[\"userId\", \"gender\", \"age\", \"occupation\", \"zip\"]\n",
        "user_pd = pd.read_csv(\"ml-1m/users.dat\", names=user_header, sep=':{2}', engine='python')\n",
        "ratings_header = [\"userId\",\"movieId\",\"rating\",\"timestamp\"]\n",
        "ratings_pd = pd.read_csv(\"ml-1m/ratings.dat\", names=ratings_header, sep=':{2}', engine='python')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYcWvVzX86y_",
        "outputId": "09bfee6b-29a4-41a0-b002-fc28509e1afc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coverting Movie Id\n",
            "Coverting User Id\n",
            "Preprocess Complete\n"
          ]
        }
      ],
      "source": [
        "#DATA PREPROCESSING#\n",
        "print(\"Coverting Movie Id\")\n",
        "#Convert Movie Id to zero index\n",
        "id_to_index = dict()\n",
        "index_to_id = dict()\n",
        "for i in range(0, len(movie_pd)) :\n",
        "    index_to_id[i] = movie_pd.iloc[i].movieId\n",
        "    id_to_index[movie_pd.iloc[i].movieId] = i\n",
        "movie_pd['movieId'] = movie_pd['movieId'].map(lambda id: id_to_index[id])\n",
        "ratings_pd['movieId'] = ratings_pd['movieId'].map(lambda id: id_to_index[id])\n",
        "\n",
        "print(\"Coverting User Id\")\n",
        "#Covert User Id to zero index\n",
        "for i in range(0, len(user_pd)) :\n",
        "    id_to_index[user_pd.iloc[i].userId] = i\n",
        "user_pd['userId'] = user_pd['userId'].map(lambda id: id_to_index[id])\n",
        "ratings_pd['userId'] = ratings_pd['userId'].map(lambda id: id_to_index[id])\n",
        "\n",
        "#Get data lengths\n",
        "movies_size= len(movie_pd)\n",
        "user_size = ratings_pd[\"userId\"].nunique()\n",
        "#normalize rating\n",
        "ratings_pd['rating'] = (ratings_pd['rating'] - ratings_pd['rating'].min()) / (ratings_pd['rating'].max() - ratings_pd['rating'].min())    \n",
        "print(\"Preprocess Complete\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mvva326B9LJP"
      },
      "outputs": [],
      "source": [
        "#Load Previous Sample\n",
        "host_path=\"/content/drive/MyDrive/Samples/\"\n",
        "train_pd = pd.read_csv(host_path + 'train_pd.csv')\n",
        "test_pd = pd.read_csv(host_path + 'test_pd.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWQpYATA9Mso"
      },
      "outputs": [],
      "source": [
        "#HYPER PARAMS\n",
        "args = {\n",
        "    \"batch_size\" : 512,\n",
        "    \"embedding_size\" : 25,\n",
        "    \"epoch\": 1,\n",
        "    \"lr\": 0.1,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mMsVTYF9NxT"
      },
      "outputs": [],
      "source": [
        "class ItemDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        movie_id = torch.tensor(ratings_pd.iloc[index][\"movieId\"], dtype=torch.long)\n",
        "        user_id =  torch.tensor(ratings_pd.iloc[index][\"userId\"], dtype=torch.long)\n",
        "        label = torch.tensor(ratings_pd.iloc[index][\"rating\"], dtype=torch.float32)\n",
        "\n",
        "        return movie_id, user_id, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "train_dataset = ItemDataset(train_pd)\n",
        "train_loader = DataLoader(train_dataset, batch_size=args[\"batch_size\"], shuffle=True)\n",
        "test_dataset = ItemDataset(test_pd)\n",
        "test_loader = DataLoader(test_dataset, batch_size=args[\"batch_size\"], shuffle=True)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c20843pN9Sru"
      },
      "outputs": [],
      "source": [
        "loss_vals = []\n",
        "loss_validation = []\n",
        "class RatingPredModel(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(RatingPredModel, self).__init__()\n",
        "        self.user_embed = nn.Embedding(user_size, args[\"embedding_size\"], device=device)       \n",
        "        self.movie_embed = nn.Embedding(movies_size, args[\"embedding_size\"], device=device)\n",
        "        self.optimizer = optim.Adam(self.parameters())\n",
        "        self.loss_fn = nn.MSELoss()\n",
        "        self.mean_absolute_error = MeanAbsoluteError()\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Sequential(OrderedDict([\n",
        "          ('ll2', nn.Linear(128 ,256)),\n",
        "          (\"drop\",  nn.Dropout(p=0.5)),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('norm', nn.BatchNorm1d(256)),\n",
        "        ]))\n",
        "        self.fc2 = nn.Sequential(OrderedDict([\n",
        "          ('ll2', nn.Linear(256 ,128)),\n",
        "          (\"drop\",  nn.Dropout(p=0.5)),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('norm', nn.BatchNorm1d(128)),\n",
        "        ]))\n",
        "        self.fc3 = nn.Sequential(OrderedDict([\n",
        "          ('ll2', nn.Linear(128 ,64)),\n",
        "          (\"drop\",  nn.Dropout(p=0.5)),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('norm', nn.BatchNorm1d(64)),\n",
        "        ]))\n",
        "        self.combined_mlp = nn.Sequential(OrderedDict([\n",
        "          ('ll1', nn.Linear(args[\"embedding_size\"] * 2, 128)),\n",
        "          (\"drop\",  nn.Dropout(p=0.5)),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('norm', nn.BatchNorm1d(128)),\n",
        "          ('fc1',  self.fc1),\n",
        "          ('fc2',  self.fc2),\n",
        "          ('fc3',  self.fc3),\n",
        "          ('llo', nn.Linear(64 , 1)),\n",
        "\n",
        "        ]))\n",
        "\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax()\n",
        "        self.aggregation_layer = torch.nn.Conv1d(in_channels=20, out_channels=1, kernel_size=1)\n",
        "\n",
        "    def forward(self, movie_id, user_id):\n",
        "\n",
        "\n",
        "        movie_vector = self.movie_embed(movie_id)\n",
        "        user_vector = self.user_embed(user_id)\n",
        "\n",
        "\n",
        "        #concat\n",
        "        combined = torch.cat((movie_vector,user_vector), dim=1)\n",
        "        return  self.combined_mlp(combined)\n",
        "\n",
        "    \n",
        "    \n",
        "    def one_epoch(self,train_loader):\n",
        "        running_loss = 0.\n",
        "        last_loss = 0.\n",
        "        for i,data in enumerate(train_loader):\n",
        "            movie_id, user_id, label  = data\n",
        "            movie_id, user_id, label = movie_id.to(device), user_id.to(device), label.to(device)\n",
        "\n",
        "            self.zero_grad()\n",
        "            outputs = self.forward(movie_id, user_id).squeeze()\n",
        "            loss = self.loss_fn(outputs, label)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            if i % 100 == 99:\n",
        "                last_loss = running_loss / 100 # loss per batch\n",
        "                print('  batch {}/{} loss: {}'.format(i + 1, len(train_loader), last_loss))\n",
        "\n",
        "                running_loss = 0.\n",
        "        return last_loss\n",
        "    def fit(self, train_loader, epoch=args[\"epoch\"], lr=args[\"lr\"]):\n",
        "        \n",
        "        for ep in range(epoch) :\n",
        "            print('EPOCH {}:'.format(ep + 1))\n",
        "            self.train(True)\n",
        "            avg_loss = self.one_epoch(train_loader)\n",
        "            self.train(False)\n",
        "            running_vloss = 0.0\n",
        "            for i, vdata in enumerate(test_loader):\n",
        "                vmovie_id, vuser_id, vlabels  = vdata \n",
        "                vmovie_id, vuser_id, vlabels = vmovie_id.to(device), vuser_id.to(device), vlabels.to(device)\n",
        "\n",
        "                \n",
        "                voutputs = self.forward(vmovie_id, vuser_id).squeeze()\n",
        "                vloss = self.loss_fn(voutputs, vlabels)\n",
        "                running_vloss += vloss\n",
        "            avg_vloss = running_vloss / (i + 1)\n",
        "            print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "            loss_vals.append(avg_loss)\n",
        "            loss_validation.append(avg_vloss)\n",
        "            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "            model_path = '/content/drive/MyDrive/weights/movierec/simplenorm_{}_{}_{}_{}'.format(timestamp, ep+1 ,avg_loss, avg_vloss)\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "    def get_metrics(self):\n",
        "      with torch.no_grad():\n",
        "            running_rmse = 0\n",
        "            running_mae = 0\n",
        "            for i, vdata in enumerate(test_loader):\n",
        "                vmovie_id, vuser_id, vlabels  = vdata \n",
        "                vmovie_id, vuser_id, vlabels = vmovie_id.to(device), vuser_id.to(device), vlabels.to(device)\n",
        "\n",
        "                \n",
        "                voutputs = self.forward(vmovie_id, vuser_id).squeeze()\n",
        "                running_rmse +=  torch.sqrt(self.loss_fn(voutputs, vlabels))\n",
        "                running_mae += self.mean_absolute_error(voutputs,vlabels)\n",
        "            rmse =  running_rmse / (i + 1)\n",
        "            mae = running_mae / (i + 1)\n",
        "            print('RMSE loss: {}\\tMAE{} '.format(rmse, mae))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNYORJba_djX"
      },
      "outputs": [],
      "source": [
        "model = RatingPredModel(args).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"/content/drive/MyDrive/weights/movierec/simplenorm_20230331_181435_9_0.7740550613403321_0.4808712303638458\"\n",
        "model.load_state_dict(torch.load(PATH, map_location=torch.device(device)), strict=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JSB4dMIyw91",
        "outputId": "cd0e42ea-77bc-4142-9952-44f29947f08a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MrVqv2gq_feE"
      },
      "outputs": [],
      "source": [
        "model.fit(train_loader, epoch=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdunHzHxngWd"
      },
      "outputs": [],
      "source": [
        "def ranking(query_liked):\n",
        "    with torch.no_grad():\n",
        "        weights = model.movie_embed.weight.detach().cpu().numpy()\n",
        "        query_res = weights[query_liked].sum(axis=0)\n",
        "\n",
        "        outs = list()\n",
        "        for idx,movie in movie_pd[\"title\"].items():\n",
        "            movie = weights[idx]\n",
        "            vector_dot = np.dot(movie, query_res)\n",
        "            movie_1_length = np.linalg.norm(movie,2)\n",
        "            query_length = np.linalg.norm(query_res,2)\n",
        "            cosine_dist =  (vector_dot / (movie_1_length * query_length))\n",
        "            outs.append(cosine_dist)\n",
        "        return torch.tensor(np.stack(outs,0))\n",
        "    \n",
        "def display_top_k(score, indices, k=5):\n",
        "    top_scores = score[:k]\n",
        "    top_indic = indices[:k]\n",
        "    top_names = []\n",
        "    top_generes = []\n",
        "    for movie_id in top_indic:\n",
        "        top_names.append(movie_pd.loc[movie_id.item()][\"title\"])\n",
        "        top_generes.append(movie_pd.loc[movie_id.item()][\"genres\"])\n",
        "        \n",
        "    df = pd.DataFrame({\n",
        "        \"score_key\": top_scores.numpy(),\n",
        "        'titles':top_names,\n",
        "        'genres': top_generes\n",
        "    })\n",
        "    print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_Y5PJYEnkSo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b85b07d3-1c37-43da-920f-04e1336e5d74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-6ddbc22f733f>:6: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
            "  movie_id = torch.tensor(ratings_pd.iloc[index][\"movieId\"], dtype=torch.long)\n",
            "<ipython-input-6-6ddbc22f733f>:7: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
            "  user_id =  torch.tensor(ratings_pd.iloc[index][\"userId\"], dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE loss: 0.884240984916687\tMAE0.7217465043067932 \n"
          ]
        }
      ],
      "source": [
        "model.get_metrics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVbnduXOnkZK",
        "outputId": "bbddf1a2-4e69-4bbe-cd66-39d6851fc4c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===========COSINE SIMILARITY===================\n",
            "   score_key                                     titles  \\\n",
            "0   1.000000  Star Wars: Episode IV - A New Hope (1977)   \n",
            "1   0.666918                    Army of Darkness (1993)   \n",
            "2   0.638077                            Bad Boys (1995)   \n",
            "3   0.617600                 Bedrooms & Hallways (1998)   \n",
            "4   0.608532                 Looking for Richard (1996)   \n",
            "5   0.588477                       Stealing Home (1988)   \n",
            "6   0.577025                    Harold and Maude (1971)   \n",
            "7   0.572028                              Picnic (1955)   \n",
            "8   0.555117           Silence of the Lambs, The (1991)   \n",
            "9   0.541753                         Clean Slate (1994)   \n",
            "\n",
            "                                  genres  \n",
            "0        Action|Adventure|Fantasy|Sci-Fi  \n",
            "1  Action|Adventure|Comedy|Horror|Sci-Fi  \n",
            "2                                 Action  \n",
            "3                         Comedy|Romance  \n",
            "4                      Documentary|Drama  \n",
            "5                                  Drama  \n",
            "6                                 Comedy  \n",
            "7                                  Drama  \n",
            "8                         Drama|Thriller  \n",
            "9                                 Comedy  \n"
          ]
        }
      ],
      "source": [
        "query_liked = [0] #Toy Story\n",
        "# query_liked = [224] #Star  Wars\n",
        "query_liked = [257] #Pulp Fiction\n",
        "# query_liked = [1192] \n",
        "\n",
        "\n",
        "topk = 10\n",
        "\n",
        "print(\"===========COSINE SIMILARITY===================\")\n",
        "score, indices = ranking(query_liked).sort(descending=True)\n",
        "display_top_k(score,indices, topk)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics(k, thresh):\n",
        "  score = 0.0\n",
        "  total = 0.0\n",
        "\n",
        "  precisions = dict()\n",
        "  recalls = dict()\n",
        "  for id, pred in predictions.items():\n",
        "    predictions[id].sort(key = lambda x: x[1], reverse=True)\n",
        "\n",
        "    n_rel = sum((true_r >= thresh) for (_, true_r) in pred)\n",
        "    n_rec_k = sum((est >= thresh) for (est, _) in pred[:k])\n",
        "    n_rel_and_rec_k = sum(\n",
        "        ((true_r >= thresh) and (est >= thresh))\n",
        "        for (est, true_r) in pred[:k]\n",
        "    )\n",
        "\n",
        "    precisions[id] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
        "    recalls[id] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
        "  return precisions, recalls\n",
        "  #   for rating in pred[:k]:\n",
        "  #     total += 1.0\n",
        "  #     if rating[1] >= thresh:\n",
        "  #       score += 1.0\n",
        "  # print(score/total)\n",
        "\n",
        "\n",
        "p, r = get_metrics(5, 0.365)\n",
        "  \n",
        "avg_p = sum(p.values()) / len(p.values()) * 100\n",
        "avg_r = sum(r.values()) / len(r.values()) * 100\n",
        "\n",
        "\n",
        "print(f\"Precision: {avg_p}\\tRecall: {avg_r}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP-BAmfZ0IRk",
        "outputId": "5cd9724f-56ad-4240-cede-bd5d46ad63e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 49.00000000000001\tRecall: 66.33928571428571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "predictions = defaultdict(list)\n",
        "model.eval()\n",
        "for userid, user in user_pd[:20].iterrows():\n",
        "  print(f\"{userid+1}/{len(user_pd[:20])}\")\n",
        "  for movieid, movie in movie_pd.iterrows():\n",
        "    movie_id = torch.tensor([movie['movieId']], dtype=torch.long).to(device)\n",
        "    user_id = torch.tensor([user['userId']] , dtype=torch.long ).to(device)\n",
        "\n",
        "    pred = model.forward(movie_id, user_id).item()\n",
        "    predictions[user_id.item()].append((movie_id.item(), pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTlGeppI0LVo",
        "outputId": "8d763e9e-4c97-45de-f6dc-e82695f82b56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/20\n",
            "2/20\n",
            "3/20\n",
            "4/20\n",
            "5/20\n",
            "6/20\n",
            "7/20\n",
            "8/20\n",
            "9/20\n",
            "10/20\n",
            "11/20\n",
            "12/20\n",
            "13/20\n",
            "14/20\n",
            "15/20\n",
            "16/20\n",
            "17/20\n",
            "18/20\n",
            "19/20\n",
            "20/20\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}